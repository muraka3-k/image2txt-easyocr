{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 画像処理用\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "### OCR処理用\n",
    "import easyocr\n",
    "\n",
    "### jupyter表示用\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"input/sample_img2.jpg\"\n",
    "\n",
    "img = cv2.imread(input_file_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_tmp = copy.deepcopy(img)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 大津の手法による二値化処理\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret,bin_img = cv2.threshold(gray_img, 10, 255, cv2.THRESH_OTSU)\n",
    "plt.imshow(cv2.cvtColor(bin_img, cv2.COLOR_GRAY2BGR))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 規定以上の大きい領域を抽出する関数\n",
    "def findLargeArea(bin_img, th_area: int = 10000):\n",
    "    # 輪郭抽出\n",
    "    contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 面積の大きいもののみ選別\n",
    "    large_areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > th_area:\n",
    "            epsilon = 0.0001*cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt,epsilon, True)\n",
    "            large_areas.append([area, approx])\n",
    "    large_areas = sorted(large_areas, reverse=True, key=lambda data: data[0])\n",
    "    return [ area[1] for area in large_areas]\n",
    "\n",
    "### 最大領域の抽出\n",
    "### 規定以上の大きい領域を抽出する関数を利用（findLargeArea）\n",
    "def findMaxArea(bin_img, th_area: int = 10000):\n",
    "    return findLargeArea(bin_img, th_area)[0]\n",
    "\n",
    "\n",
    "max_areas = findMaxArea(bin_img)\n",
    "cv2.drawContours(img_tmp,max_areas,-1,(0,255,0),3)\n",
    "\n",
    "print(len(max_areas))\n",
    "plt.imshow(img_tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 重心を算出する関数\n",
    "def calCenter(area):\n",
    "    mu = cv2.moments(area)\n",
    "    x  = int(mu[\"m10\"] / mu[\"m00\"])\n",
    "    y  = int(mu[\"m01\"] / mu[\"m00\"])\n",
    "    return x, y\n",
    "\n",
    "x, y = calCenter(max_areas)\n",
    "print(x, y)\n",
    "\n",
    "cv2.circle(img_tmp, (x,y), 4, 100, 2, 4)\n",
    "\n",
    "plt.imshow(img_tmp)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 重心から遠い座標を中心に、近似する座標を除外する処理\n",
    "### [out] max_point：dist_listの中で一番重心から遠い座標\n",
    "def deleteNearPoint(dist_list, th_dist):\n",
    "    dist_list   = sorted(dist_list, reverse=True, key=lambda data: data[0])\n",
    "    _,far_point = dist_list[0]\n",
    "    for n in reversed(range(len(dist_list))):\n",
    "        cal_dist = np.linalg.norm(dist_list[n][1] - far_point)\n",
    "        if th_dist > cal_dist:\n",
    "            dist_list.pop(n)\n",
    "            # print(len(dist_list))\n",
    "    return far_point, dist_list\n",
    "\n",
    "### 重心から遠い4座標を決定する関数\n",
    "def detectPoint(area, x, y, th_coe: float = 0.75):\n",
    "    out_points = []\n",
    "\n",
    "    ### 重心からの距離を算出\n",
    "    result_list = []\n",
    "    center = np.array([x, y])\n",
    "    for point in area:\n",
    "        result_list.append([np.linalg.norm(center - point), point])\n",
    "\n",
    "    ### 重心から一番遠い座標に近似する座標と判定する閾値の算出\n",
    "    sort_list  = sorted(result_list, reverse=True, key=lambda data: data[0])\n",
    "    max_dist,_ = sort_list[0]\n",
    "    th_dist    = max_dist * th_coe\n",
    "    while len(sort_list):\n",
    "        far_point, sort_list = deleteNearPoint(sort_list, th_dist)\n",
    "        out_points.append(far_point)\n",
    "        # print(len(out_points))\n",
    "    return out_points[:4]\n",
    "\n",
    "c_points = detectPoint(max_areas, x, y)\n",
    "print(c_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "for area in c_points:\n",
    "    cv2.circle(img_tmp, (area[0]), 4, 100, 20, 4)\n",
    "plt.imshow(img_tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpPerspective(in_rgb_img, points):\n",
    "    try:\n",
    "\n",
    "        # 変換前4点の座標　p1:左上　p2:左下 p3:右下 p4:右上\n",
    "        points = sorted(points, key=lambda data: data[0][1])\n",
    "        upside_point = sorted(points[:2], key=lambda data: data[0][0])\n",
    "        downside_point = sorted(points[2:], key=lambda data: data[0][0])\n",
    "        \n",
    "        p1 = upside_point[0][0]\n",
    "        p2 = downside_point[0][0]\n",
    "        p3 = downside_point[1][0]\n",
    "        p4 = upside_point[1][0]\n",
    "\n",
    "        print(\"P1:\", p1)\n",
    "        print(\"P2:\", p2)\n",
    "        print(\"P3:\", p3)\n",
    "        print(\"P4:\", p4)\n",
    "\n",
    "        #　幅取得\n",
    "        o_width_max = max(np.linalg.norm(p4 - p1), np.linalg.norm(p2 - p3))\n",
    "        o_width_min = min(np.linalg.norm(p4 - p1), np.linalg.norm(p2 - p3))\n",
    "        # 比率調整\n",
    "        ratio    = o_width_max / o_width_min\n",
    "        o_width  = math.floor(o_width_min * ratio)\n",
    "\n",
    "        #　高さ取得\n",
    "        o_height = max(np.linalg.norm(p2 - p1), np.linalg.norm(p4 - p3))\n",
    "        o_height = math.floor(o_height * ratio)\n",
    "        \n",
    "        print(\"length_w:{}   length_h:{}\".format(o_width, o_height))\n",
    "\n",
    "        # 変換前の4点\n",
    "        src = np.float32([p1, p2, p3, p4])\n",
    "\n",
    "        # 変換後の4点\n",
    "        dst = np.float32([[0, 0],[0, o_height],[o_width, o_height],[o_width, 0]])\n",
    "\n",
    "        # 変換行列\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "        # 射影変換・透視変換する\n",
    "        output = cv2.warpPerspective(in_rgb_img, M,(o_width, o_height))\n",
    "    except Exception as e:\n",
    "        print(\"error:{}\".format(e.args))\n",
    "        return None\n",
    "\n",
    "    return output\n",
    "daikei = warpPerspective(img, c_points)\n",
    "\n",
    "plt.imshow(daikei)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f904bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['ja', 'en'])#日本語：ja, 英語：en\n",
    "\n",
    "results = reader.readtext(daikei)\n",
    "for result in results:\n",
    "    print(\"text:\", result[1], result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856de5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatOCRpoints2Json(points):\n",
    "    output_points = copy.deepcopy(points)\n",
    "    for point in output_points:\n",
    "        point[0] = int(point[0])\n",
    "        point[1] = int(point[1])\n",
    "    return output_points\n",
    "\n",
    "def makeOCRresult2Json(ocr_results):\n",
    "    output_list = []\n",
    "    for oce_result in ocr_results:\n",
    "        output               = {}\n",
    "        output[\"Text\"]       = oce_result[1]\n",
    "        output[\"Points\"]     = formatOCRpoints2Json(oce_result[0])\n",
    "        output[\"Confidence\"] = oce_result[2]\n",
    "        output_list.append(output)\n",
    "    return output_list\n",
    "\n",
    "result_json = {}\n",
    "result_json[\"File\"] = input_file_path\n",
    "result_json[\"Result\"] = makeOCRresult2Json(results)\n",
    "with open('search_result.json', 'w') as f:\n",
    "    json.dump(result_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoxImage(img, points):\n",
    "    print(\"  dwar points:{}, {}, {}, {}\".\\\n",
    "        format(tuple(points[0]), tuple(points[1]),\\\n",
    "               tuple(points[2]), tuple(points[3])))\n",
    "\n",
    "    return cv2.polylines(img, [points], True, (255, 0, 0), thickness = 2)\n",
    "\n",
    "def drawOCRResultImage(img, ocr_results):\n",
    "    for oce_result in ocr_results:\n",
    "        print(oce_result[1])\n",
    "        ### OCRの座標情報はList型のため、numpyに変換する\n",
    "        points = np.array(oce_result[0],dtype=np.int32)\n",
    "        drawBoxImage(img, points)\n",
    "\n",
    "drawOCRResultImage(daikei, results)\n",
    "plt.imshow(daikei)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c73adf2c0cac92dc7d69659d3db7ef05af856165b06f57415eef9914a444074"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
